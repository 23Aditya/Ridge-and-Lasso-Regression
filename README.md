# Ridge-and-Lasso-Regression

### L1 regularization
L1 regularization, also known as the Lasso technique, is a method for regularizing linear models that forces the weights of the model to be sparse by adding an L1 penalty term to the cost function. This in turn encourages the model to select only a few features from the available feature set, leading to a more parsimonious model. The objective of the L1 regularization is to reduce the magnitude of the coefficients of the features, which can help reduce the complexity of the model and avoid overfitting.

### L2 regularization
L2 regularization is a type of regularization used to prevent overfitting in machine learning models. It works by adding a penalty term to the loss function of the model, which is the sum of the squares of the weights. This penalty term reduces the magnitude of the weights, resulting in a smoother model, which is less prone to overfitting. L2 regularization can also be used to reduce the number of parameters in the model, which helps reduce the amount of memory required for training.![L1 and L2 ](https://user-images.githubusercontent.com/68725514/225577404-3dd7ecb7-4649-42ee-a195-dec362b690c6.jpg)
